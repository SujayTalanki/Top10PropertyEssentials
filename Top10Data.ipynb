{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7695f61b",
   "metadata": {},
   "source": [
    "## Top 10 Property Essentials Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6538905",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47edf295",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nInvalid named renderer(s) received: ['google-chrome']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\talan\\Downloads\\Top10PropertyEssentials-20230914T210048Z-001\\Top10PropertyEssentials\\Top10Data.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/talan/Downloads/Top10PropertyEssentials-20230914T210048Z-001/Top10PropertyEssentials/Top10Data.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/talan/Downloads/Top10PropertyEssentials-20230914T210048Z-001/Top10PropertyEssentials/Top10Data.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/talan/Downloads/Top10PropertyEssentials-20230914T210048Z-001/Top10PropertyEssentials/Top10Data.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m pio\u001b[39m.\u001b[39mrenderers\u001b[39m.\u001b[39mdefault \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgoogle-chrome\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/talan/Downloads/Top10PropertyEssentials-20230914T210048Z-001/Top10PropertyEssentials/Top10Data.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\plotly\\io\\_renderers.py:152\u001b[0m, in \u001b[0;36mRenderersConfig.default\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m# Store defaults name and list of renderer(s)\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m renderer_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_coerce_renderers(value)\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_name \u001b[39m=\u001b[39m value\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_renderers \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m[name] \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m renderer_names]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\plotly\\io\\_renderers.py:219\u001b[0m, in \u001b[0;36mRenderersConfig._validate_coerce_renderers\u001b[1;34m(self, renderers_string)\u001b[0m\n\u001b[0;32m    217\u001b[0m         invalid \u001b[39m=\u001b[39m [name \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m renderer_names \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m]\n\u001b[0;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m invalid:\n\u001b[1;32m--> 219\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m                 \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39mInvalid named renderer(s) received: {}\"\"\"\u001b[39;00m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    222\u001b[0m                     \u001b[39mstr\u001b[39m(invalid)\n\u001b[0;32m    223\u001b[0m                 )\n\u001b[0;32m    224\u001b[0m             )\n\u001b[0;32m    226\u001b[0m         \u001b[39mreturn\u001b[39;00m renderer_names\n",
      "\u001b[1;31mValueError\u001b[0m: \nInvalid named renderer(s) received: ['google-chrome']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash_bootstrap_templates import load_figure_template\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import itertools\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#!pip install openpyxl -- uncomment if running for the first time\n",
    "#also gotta install the other packages as well!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e32d1eb8",
   "metadata": {},
   "source": [
    "### Converting xlsx file to csv's \n",
    "\n",
    "**If you have the CSV'a ignore the code and leave it commented out**  \n",
    "\n",
    "**If csv's are outdated and you need to unpack an excel file, uncomment the block, replace the \"excel_file\" with the correct file path and run ONLY ONCE**\n",
    "\n",
    "**once you have the csv's in the same directory, comment the block out and don't run again!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db37bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THE \"excel_file\" IS IN THE SAME DIRECTORY!\n",
    "\n",
    "# excel_file = 'importData/COMMENTARY.xlsx'\n",
    "# all_sheets = pd.read_excel(excel_file, sheet_name=None)\n",
    "# sheets = all_sheets.keys()\n",
    "\n",
    "# for sheet_name in sheets:\n",
    "#     sheet = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "#     sheet.to_csv(\"%s.csv\" % sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6ae98",
   "metadata": {},
   "source": [
    "### Reading dataframes and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc96e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv('importData/ATTRIBUTES.csv')\n",
    "inspection = pd.read_csv('importData/INSPECTION.csv')\n",
    "invoice = pd.read_csv('importData/INVOICE.csv')\n",
    "question = pd.read_csv('importData/QUESTION.csv')\n",
    "scores = pd.read_csv('importData/SCORES.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aae6dcf",
   "metadata": {},
   "source": [
    "### Code to extract month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bc088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month(date):\n",
    "    date_list = date.split('-')\n",
    "    month = int(date_list[1])\n",
    "    return month\n",
    "\n",
    "def extract_year(date):\n",
    "    date_list = date.split('-')\n",
    "    year = int(date_list[0])\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0c87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection['MONTH'] = inspection['Created'].apply(extract_month)\n",
    "inspection['YEAR'] = inspection['Created'].apply(extract_year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8483586",
   "metadata": {},
   "source": [
    "### Creating bar chart of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809c32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(question, phrase_size, k):\n",
    "\n",
    "    def create_dictionary(question, phrase_size):\n",
    "        df = scores[scores['QUESTION'] == question]\n",
    "        comments = df['COMMENT'].dropna()\n",
    "        counts = {}\n",
    "        for sentence in comments:\n",
    "            lowercase = sentence.lower()\n",
    "            cleaned = re.sub(\"[^\\w\\d'\\s]+\",'', lowercase).strip()\n",
    "            if phrase_size == 1:\n",
    "                words = cleaned.split()\n",
    "                useless_words = stopwords.words(\"english\")\n",
    "                for word in words:\n",
    "                    if word in counts.keys() and word not in useless_words:\n",
    "                        counts[word] += 1\n",
    "                    elif word not in counts.keys() and word not in useless_words:\n",
    "                        counts[word] = 1\n",
    "            else:\n",
    "                pairs = list(ngrams(cleaned.split(), phrase_size))\n",
    "                useless_words = set(stopwords.words('english'))\n",
    "                for pair in pairs:\n",
    "                    key = \" \".join(pair)\n",
    "                    if key in counts.keys():\n",
    "                        counts[key] += 1\n",
    "                    elif key not in counts.keys():\n",
    "                        counts[key] = 1\n",
    "        sorted_words = dict(sorted(counts.items(), key=lambda item: item[1], reverse=True))\n",
    "        return sorted_words   \n",
    "\n",
    "    def top_k_items(k, dictionary):\n",
    "        top_items = dict(list(dictionary.items())[0:k])\n",
    "        return top_items\n",
    "\n",
    "    def top_k_dictionary(question, phrase_size, k):\n",
    "        words = create_dictionary(question, phrase_size)\n",
    "        sorted_dic = dict(sorted(words.items(), key=lambda item: item[1], reverse=True))\n",
    "        top_items = top_k_items(2*k+5, sorted_dic)\n",
    "        return top_items\n",
    "    \n",
    "    def create_embeddings(top_items):\n",
    "        sentences = list(top_items.keys())\n",
    "        counts = list(top_items.values())\n",
    "        model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "        sentences_with_embeddings = list(zip(sentences, sentence_embeddings, counts))\n",
    "        return sentences_with_embeddings\n",
    "    \n",
    "    def delete_similar_phrases(top_items, phrases_embeddings):\n",
    "        sentences = list(top_items.keys())\n",
    "        kept = dict.fromkeys(sentences, True)\n",
    "        combos = list(itertools.combinations(phrases_embeddings, 2))\n",
    "        for combo in combos:\n",
    "            if kept[combo[0][0]] == False or kept[combo[1][0]] == False:\n",
    "                continue\n",
    "            similarity = util.pytorch_cos_sim(combo[0][1], combo[1][1]).item()\n",
    "            if similarity >= 0.85:\n",
    "                if combo[1][2] > combo[0][2]:\n",
    "                    kept[combo[0][0]] = False\n",
    "                else:\n",
    "                    kept[combo[1][0]] = False\n",
    "        return kept\n",
    "    \n",
    "    def reformat(reduced, original_dict):\n",
    "        final_phrases = []\n",
    "        for key, value in reduced.items():\n",
    "            if value == True:\n",
    "                final_phrases.append(key)\n",
    "        filtered_dict = {}\n",
    "        for phrase in final_phrases:\n",
    "            filtered_dict[phrase] = original_dict[phrase]\n",
    "        return filtered_dict\n",
    "    \n",
    "    top_items = top_k_dictionary(question, phrase_size, k)\n",
    "    embeddings = create_embeddings(top_items)\n",
    "    kept_dictionary = delete_similar_phrases(top_items, embeddings)\n",
    "    reduced_dictionary = reformat(kept_dictionary, top_items)\n",
    "    \n",
    "    return reduced_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aafcbd",
   "metadata": {},
   "source": [
    "### Code for the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fafb5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "app = Dash(__name__, external_stylesheets=[dbc.themes.DARKLY])\n",
    "style = {'margin-left':'7px', 'margin-top':'7px'}\n",
    "sidebar_style = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"22rem\",\n",
    "    \"padding\": \"1rem 1rem\",\n",
    "    \"background-color\": \"black\",\n",
    "}\n",
    "\n",
    "sidebar = html.Div([\n",
    "        html.H2(\"Options\"),\n",
    "        html.Hr(),\n",
    "        html.P(\n",
    "            \"Choose values for each option below\", className=\"lead\"\n",
    "        ),\n",
    "        dbc.Nav(\n",
    "            [\n",
    "                question_input := dcc.Dropdown(id='Select Question', options=scores['QUESTION'].unique(), value='Trees'),\n",
    "                html.Br(),\n",
    "                size_input := dcc.Input(type='number', value=3, min=1, max=10),\n",
    "                html.Br(),\n",
    "                k_input := dcc.Input(type='number', value=20, min=1, max=50)\n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "        ),\n",
    "    ],\n",
    "    style=sidebar_style,\n",
    ")\n",
    "\n",
    "app.layout = html.Div(children = [\n",
    "                dbc.Row([\n",
    "                    dbc.Col(),\n",
    "                    dbc.Col(html.H1('Common Phrases per Reason'), width = 9, style = {'margin-left':'7px','margin-top':'7px'})\n",
    "                    ]),\n",
    "                dbc.Row(\n",
    "                    [dbc.Col(sidebar),\n",
    "                     dbc.Col(gr := dcc.Graph(id = 'graph2', figure = {}), width = 9, style = {'margin-left':'15px', 'margin-top':'7px', 'margin-right':'15px'})\n",
    "                    ])\n",
    "    ]\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    Output(gr, component_property='figure'),\n",
    "    Input(question_input, 'value'),\n",
    "    Input(size_input, 'value'),\n",
    "    Input(k_input, 'value')\n",
    ")\n",
    "def update_graph(question_value, size_value, k):\n",
    "    top_items = build_model(question_value, size_value, k)\n",
    "    data = pd.DataFrame(list(top_items.items()), columns=['phrase', 'count'])\n",
    "    fig = px.bar(data, x='phrase', y='count')\n",
    "    #fig.show(renderer='browser')\n",
    "    fig.update_layout(mapbox_style='carto-positron')\n",
    "    return fig\n",
    "\n",
    "load_figure_template('DARKLY')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False, jupyter_mode=\"external\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1420c5a6",
   "metadata": {},
   "source": [
    "### Code that went into Power BI (it's a bit different in Power BI when accounting for the parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ccb22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember to add useless to the cell, it won't run in power bi!\n",
    "def scratch(question, phrase_size, k):\n",
    "\n",
    "    useless = set({'a','about','above','after','all',\n",
    "        'an','and','any','are',\"aren't\",'as','at','be','because',\n",
    "        'been','being','between','both','but','by','can',\"couldn't\",\n",
    "        'did',\"didn't\",'do','does',\"doesn't\",'doing',\"don't\",'down',\n",
    "        'during','each','few','for','from','had',\"hadn't\",'has',\n",
    "        \"hasn't\",'have',\"haven't\",'having','he','her','here',\n",
    "        'hers','herself','him','himself','his','how','i','if',\n",
    "        'in','into','is',\"isn't\",'it',\"it's\",'its','just',\n",
    "        'me',\"mightn't\",'more','my','myself',\"needn't\",\n",
    "        'no','nor','not','now','of','off','on','once',\n",
    "        'only','or','other','our','ours','ourselves','out',\n",
    "        'over','own','same','she',\"she's\",'should',\"should've\",\n",
    "        \"shouldn't\",'so','some','than','that','the','their',\n",
    "        'theirs','them','then','there','these','they','this',\n",
    "        'those','through','to','too','under','very','was',\n",
    "        \"wasn't\",'we','were',\"weren't\",'what','when','where',\n",
    "        'which','while','why','will','with',\"won't\",\"wouldn't\"})\n",
    "\n",
    "    def combinations(iterable, r):\n",
    "        pool = tuple(iterable)\n",
    "        n = len(pool)\n",
    "        if r > n:\n",
    "            return\n",
    "        indices = list(range(r))\n",
    "        yield tuple(pool[i] for i in indices)\n",
    "        while True:\n",
    "            for i in reversed(range(r)):\n",
    "                if indices[i] != i + n - r:\n",
    "                    break\n",
    "            else:\n",
    "                return\n",
    "            indices[i] += 1\n",
    "            for j in range(i+1, r):\n",
    "                indices[j] = indices[j-1] + 1\n",
    "            yield tuple(pool[i] for i in indices)\n",
    "\n",
    "    def count_common(string1, string2):\n",
    "        str1, str2 = string1.split(), string2.split()\n",
    "        set1 = set(str1)\n",
    "        common = len(set1.intersection(str2))\n",
    "        # if (\"nstb\" in set1 or \"ntb\" in set1) and (\"nstb\" in str2 or \"ntb\" in str2):\n",
    "        #     common += 1\n",
    "        return common/len(str1)\n",
    "    \n",
    "    def clean(string):\n",
    "        replacements = {\n",
    "            'need to be': 'ntb',\n",
    "            'needs to be': 'nstb'\n",
    "        }\n",
    "        for key, value in replacements.items():\n",
    "            string = string.replace(key, value)\n",
    "        return string\n",
    "\n",
    "    def create_dictionary(question, phrase_size, useless):\n",
    "        df = scores[scores['QUESTION'] == question]\n",
    "        comments = df['COMMENT'].dropna()\n",
    "        counts = {}\n",
    "        for sentence in comments:\n",
    "            lowercase = sentence.lower()\n",
    "            cleaned = clean(re.sub(\"[^\\w\\d'\\s]+\",'', lowercase).strip())\n",
    "            if phrase_size == 1:\n",
    "                words = cleaned.split()\n",
    "                for word in words:\n",
    "                    if word in counts.keys() and word not in useless:\n",
    "                        counts[word] += 1\n",
    "                    elif word not in counts.keys() and word not in useless:\n",
    "                        counts[word] = 1\n",
    "            else:\n",
    "                pairs = list(ngrams(cleaned.split(), phrase_size))\n",
    "                for pair in pairs:\n",
    "                    key = \" \".join(pair)\n",
    "                    if key in counts.keys():\n",
    "                        counts[key] += 1\n",
    "                    elif key not in counts.keys():\n",
    "                        counts[key] = 1\n",
    "        sorted_words = dict(sorted(counts.items(), key=lambda item: item[1], reverse=True))\n",
    "        return sorted_words\n",
    "\n",
    "    def top_k_items(k, dictionary):\n",
    "        top_items = dict(list(dictionary.items())[0:k])\n",
    "        return top_items\n",
    "\n",
    "    def top_k_dictionary(question, phrase_size, k):\n",
    "        words = create_dictionary(question, phrase_size, useless)\n",
    "        sorted_dic = dict(sorted(words.items(), key=lambda item: item[1], reverse=True))\n",
    "        top_items = top_k_items(2*k+5, sorted_dic)\n",
    "        return top_items\n",
    "    \n",
    "    def delete_similar_phrases(top_items):\n",
    "        tuples = list(top_items.items())\n",
    "        phrases = list(map(lambda x: x[0], tuples))\n",
    "        kept = dict.fromkeys(phrases, True)\n",
    "        combos = list(combinations(tuples, 2))\n",
    "        for combo in combos:\n",
    "            if kept[combo[0][0]] == False or kept[combo[1][0]] == False:\n",
    "                continue\n",
    "            similarity = count_common(combo[0][0], combo[1][0])\n",
    "            if similarity >= 0.66:\n",
    "                if combo[1][1] > combo[0][1]:\n",
    "                    kept[combo[0][0]] = False\n",
    "                else:\n",
    "                    kept[combo[1][0]] = False\n",
    "        return kept\n",
    "    \n",
    "    def reformat(reduced, original_dict):\n",
    "        final_phrases = []\n",
    "        for key, value in reduced.items():\n",
    "            if value == True:\n",
    "                final_phrases.append(key)\n",
    "        filtered_dict = {}\n",
    "        for phrase in final_phrases:\n",
    "            filtered_dict[phrase] = original_dict[phrase]\n",
    "        return filtered_dict\n",
    "    \n",
    "    top_items = top_k_dictionary(question, phrase_size, k)\n",
    "    kept_dictionary = delete_similar_phrases(top_items)\n",
    "    reduced_dictionary = reformat(kept_dictionary, top_items)\n",
    "    \n",
    "    return reduced_dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
